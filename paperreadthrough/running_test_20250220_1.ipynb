{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Test for Paper Reaqd Through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- time: 2025-02-20\n",
    "- first trial: on pdf processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import fitz\n",
    "import toml\n",
    "import copy\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Though\"\n",
    "pdf_path = \"/home/jiezi/Code/Temp/data/2501.04682v1.pdf\"\n",
    "data_path = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apis.semanticscholar_tool import SemanticScholarKit\n",
    "\n",
    "ss = SemanticScholarKit()\n",
    "ss_metadata = ss.search_paper_by_keywords(query=title, limit=3)\n",
    "\n",
    "paper_ss_id = ss_metadata[0].get('paperId')\n",
    "print(paper_ss_id)\n",
    "\n",
    "reference_metadata = ss.get_semanticscholar_references(paper_id=paper_ss_id, limit=100)\n",
    "len(reference_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_process.pdf_outline_gen import PDFOutline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline = PDFOutline(pdf_path=pdf_path)\n",
    "toc_1 = outline.toc_extraction()\n",
    "toc_2 = outline.toc_detection()\n",
    "\n",
    "toc_1_rvsd = outline.identify_toc_appendix(toc_1)\n",
    "toc_2_rvsd = outline.identify_toc_appendix(toc_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apis.mineru_tool import MinerUKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "mineru = MinerUKit(api_key=os.getenv('MINERU_API_KEY_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mineru.batch_process_files(pdf_files=[pdf_path], if_ocr=False, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if res.status_code == 200:\n",
    "    batch_id = res.json().get('data', {}).get('batch_id')\n",
    "    print(batch_id)\n",
    "    if batch_id:\n",
    "        mineru.monitor_batch_status(batch_id=batch_id, save_path=data_path, interval=10, max_retries=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Post Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.path.basename(pdf_path)\n",
    "file_name_nosuffix = file_name.rsplit('.', 1)[0] \n",
    "processed_file_path = os.path.join(data_path, file_name_nosuffix)\n",
    "\n",
    "md_file = os.path.join(processed_file_path, \"full.md\")\n",
    "content_json_file = os.path.join(processed_file_path, \"content_list.json\")\n",
    "\n",
    "import json\n",
    "with open(content_json_file) as json_data:\n",
    "    content_json = json.load(json_data)\n",
    "\n",
    "with open(md_file, 'r', encoding='utf-8') as f:\n",
    "    markdown_content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_process.pdf_post_process import PDFProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = PDFProcess(pdf_path=pdf_path, pdf_toc=toc_1_rvsd,pdf_json=content_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.align_md_toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.align_content_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.align_reference_info(reference_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_json_rvsd_path = os.path.join(processed_file_path, \"processed_content_list.json\")\n",
    "with open(pdf_json_rvsd_path, \"w\") as file:\n",
    "    json.dump(pdf.pdf_json, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_toc_hierachy(pdf_json):\n",
    "    \"\"\"解析markdown json数据，生成树状章节结构。\n",
    "    Args:\n",
    "        pdf_json: markdown json数据列表\n",
    "    Returns:\n",
    "        树状章节结构的json数据列表\n",
    "    \"\"\"\n",
    "    toc = []\n",
    "    section_stack = []\n",
    "\n",
    "    for i, item in enumerate(pdf_json):\n",
    "        if item['type'] == 'title':\n",
    "            level = item['text_level']\n",
    "            title = item['text']\n",
    "\n",
    "            while section_stack and section_stack[-1]['level'] >= level:\n",
    "                popped_section = section_stack.pop()\n",
    "                popped_section['end_position'] = i - 1\n",
    "                if section_stack:\n",
    "                    section_stack[-1]['subsection'].append(popped_section)\n",
    "                else:\n",
    "                    toc.append(popped_section)\n",
    "\n",
    "            new_section = {'title': title, 'level': level, 'start_position': i, 'end_position': -1, 'subsection': []}\n",
    "            section_stack.append(new_section)\n",
    "\n",
    "    while section_stack:\n",
    "        popped_section = section_stack.pop()\n",
    "        popped_section['end_position'] = len(pdf_json) - 1\n",
    "        if section_stack:\n",
    "            section_stack[-1]['subsection'].append(popped_section)\n",
    "        else:\n",
    "            toc.append(popped_section)\n",
    "\n",
    "    return toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_hierachy = get_toc_hierachy(pdf.pdf_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_hierachy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def calculate_tokens(text, encoding_name=\"cl100k_base\"):\n",
    "    \"\"\"Calculates the number of tokens for a given text using a specified encoding.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.get_encoding(encoding_name)\n",
    "        num_tokens = len(encoding.encode(text))\n",
    "        return num_tokens\n",
    "    except tiktoken.EncodingError as e:\n",
    "        print(f\"Error: Encoding '{encoding_name}' not found or text encoding failed. Please check the encoding name and text format.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_hierachy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_segmentation(self, toc_hierachy, seg_text_length:Optional[int]=20000):\n",
    "    \"\"\"segment content json based on toc hierachy\"\"\"\n",
    "    pdf_texts = [item.get('text', '') for item in self.pdf_json]\n",
    "\n",
    "    all_seg_paras = []\n",
    "    for section in toc_hierachy:\n",
    "        section_paras = []\n",
    "        \n",
    "        start_pos = section['start_position']\n",
    "        end_pos = section['end_position']\n",
    "        \n",
    "        if len(tmp_text) > seg_text_length and section.get('subsection', []) != []:\n",
    "            # if the section is too long, then breakdown to subsection\n",
    "            for subsection in section.get('subsection'):\n",
    "                sub_start_pos = subsection['start_position']\n",
    "                sub_end_pos = subsection['end_position']\n",
    "                section_paras.append(self.pdf_json[sub_start_pos:sub_end_pos+1])\n",
    "                tmp_text = \"\\n\".join(pdf_texts[start_pos:end_pos+1])\n",
    "                print('subsection', subsection, len(tmp_text))\n",
    "        else:\n",
    "            section_paras.append(self.pdf_json[start_pos:end_pos+1])\n",
    "            tmp_text = \"\\n\".join(pdf_texts[start_pos:end_pos+1])\n",
    "            print('section', section, len(tmp_text))\n",
    "                \n",
    "        all_seg_paras.extend(section_paras)\n",
    "    return all_seg_paras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_seg_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seg_paras[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def restore_seg_information(self, seg_paras):\n",
    "        \"\"\"restore images, tables, references within segments\n",
    "        Args:\n",
    "            seg_paras: PDF content json organized in segments, data from gen_segmentation function\n",
    "            img_lst, tbl_lst: \n",
    "        \"\"\"\n",
    "        lines = md_text.splitlines()\n",
    "        seg_images, seg_tbls, seg_refs = [], [], []\n",
    "\n",
    "        for idx, line in enumerate(lines):\n",
    "            if line.strip() not in [\"\\n\", \"\\s\", \"\\r\", \"\"]:\n",
    "                # resore images in segment\n",
    "                for img in img_lst:\n",
    "                    md_ref = img.get('mod_md_ref', '').strip()\n",
    "                    # image cited in line but not exist in section \n",
    "                    if (md_ref not in \"\\n\".join(lines).strip()\n",
    "                        and (img.get('id') in line.strip() or img.get('title') in line.strip())):\n",
    "                        lines.insert(idx+1, md_ref)\n",
    "                        if img not in seg_images:\n",
    "                            seg_images.append(img)\n",
    "\n",
    "                    # line contains image ref but not cited in section\n",
    "                    if md_ref in line.strip():\n",
    "                        if img.get('id') not in \"\\n\".join(lines).strip() or img.get('title') in \"\\n\".join(lines).strip():\n",
    "                            lines[idx] = line.replace(md_ref, \"  \")\n",
    "                        elif img not in seg_images:\n",
    "                            seg_images.append(img)\n",
    "\n",
    "                # resore tables in segment\n",
    "                for tbl in tbl_lst:\n",
    "                    md_ref = tbl.get('mod_md_ref').strip()\n",
    "\n",
    "                    # image cited in line but not exist in section \n",
    "                    if (md_ref not in \"\\n\".join(lines).strip()\n",
    "                        and (tbl.get('id') in line.strip() or tbl.get('title') in line.strip())):\n",
    "                        lines.insert(idx+1, md_ref)\n",
    "                        if tbl not in seg_tbls:\n",
    "                            seg_tbls.append(tbl)\n",
    "\n",
    "                    # line contains image ref but not cited in section\n",
    "                    if md_ref in line.strip():\n",
    "                        if (tbl.get('id') not in \"\\n\".join(lines).strip() or tbl.get('title') in \"\\n\".join(lines).strip()):\n",
    "                            lines[idx] = line.replace(md_ref, \"  \")\n",
    "                        elif tbl not in seg_tbls:\n",
    "                            seg_tbls.append(tbl)\n",
    "\n",
    "                # restore refs in segment\n",
    "                for idx, line in enumerate(lines):\n",
    "                    if line.strip() not in [\"\\n\", \"\\s\", \"\\r\", \"\"]:\n",
    "                        for ref in ref_lst:\n",
    "                            if ref not in seg_refs:\n",
    "                                contexts = ref.get('contexts')\n",
    "                                for x in contexts:\n",
    "                                    if x.strip() in line:\n",
    "                                        seg_refs.append(ref.get('citedPaper', {}))  # get only ref paper information, neglect isInfluential, intent, etc.\n",
    "                                        break\n",
    "        \n",
    "        # append references to segments\n",
    "        if len(seg_refs) > 0:\n",
    "            lines.extend([x.get('org_md_ref') for x in ref_lst])\n",
    "\n",
    "        return \"\\n\".join(lines), seg_images, seg_tbls, seg_refs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4fun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
