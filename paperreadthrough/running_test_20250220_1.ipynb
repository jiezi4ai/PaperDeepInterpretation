{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Test for Paper Reaqd Through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- time: 2025-02-20\n",
    "- first trial: on pdf processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import fitz\n",
    "import toml\n",
    "import copy\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Though\"\n",
    "pdf_path = \"/home/jiezi/Code/Temp/data/2501.04682v1.pdf\"\n",
    "data_path = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 09:55:30,655 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/search?query=Towards+System+2+Reasoning+in+LLMs%3A+Learning+How+to+Think+With+Meta+Chain-of-Though&fields=abstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=3 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0e63a3aebf14fc7a68c0df7a922770bde5b77360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 09:55:31,846 - INFO - HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/0e63a3aebf14fc7a68c0df7a922770bde5b77360/references?fields=contexts%2Cintents%2CcontextsWithIntent%2CisInfluential%2Cabstract%2Cauthors%2CcitationCount%2CcitationStyles%2CcorpusId%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Cs2FieldsOfStudy%2Ctitle%2Curl%2Cvenue%2Cyear&offset=0&limit=100 \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from apis.semanticscholar_tool import SemanticScholarKit\n",
    "\n",
    "ss = SemanticScholarKit()\n",
    "ss_metadata = ss.search_paper_by_keywords(query=title, limit=3)\n",
    "\n",
    "paper_ss_id = ss_metadata[0].get('paperId')\n",
    "print(paper_ss_id)\n",
    "\n",
    "reference_metadata = ss.get_semanticscholar_references(paper_id=paper_ss_id, limit=100)\n",
    "len(reference_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_process.pdf_outline_gen import PDFOutline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline = PDFOutline(pdf_path=pdf_path)\n",
    "toc_1 = outline.toc_extraction()\n",
    "toc_2 = outline.toc_detection()\n",
    "\n",
    "toc_1_rvsd = outline.identify_toc_appendix(toc_1)\n",
    "toc_2_rvsd = outline.identify_toc_appendix(toc_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apis.mineru_tool import MinerUKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "mineru = MinerUKit(api_key=os.getenv('MINERU_API_KEY_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mineru.batch_process_files(pdf_files=[pdf_path], if_ocr=False, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if res.status_code == 200:\n",
    "    batch_id = res.json().get('data', {}).get('batch_id')\n",
    "    print(batch_id)\n",
    "    if batch_id:\n",
    "        mineru.monitor_batch_status(batch_id=batch_id, save_path=data_path, interval=10, max_retries=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Post Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.path.basename(pdf_path)\n",
    "file_name_nosuffix = file_name.rsplit('.', 1)[0] \n",
    "processed_file_path = os.path.join(data_path, file_name_nosuffix)\n",
    "\n",
    "md_file = os.path.join(processed_file_path, \"full.md\")\n",
    "content_json_file = os.path.join(processed_file_path, \"content_list.json\")\n",
    "\n",
    "import json\n",
    "with open(content_json_file) as json_data:\n",
    "    content_json = json.load(json_data)\n",
    "\n",
    "with open(md_file, 'r', encoding='utf-8') as f:\n",
    "    markdown_content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf_process.pdf_post_process import PDFProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = PDFProcess(pdf_path=pdf_path, pdf_toc=toc_1_rvsd,pdf_json=content_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.align_md_toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.align_content_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.align_reference_info(reference_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_json_rvsd_path = os.path.join(processed_file_path, \"processed_content_list.json\")\n",
    "with open(pdf_json_rvsd_path, \"w\") as file:\n",
    "    json.dump(pdf.pdf_json, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "pdf_json_rvsd_path = \"/home/jiezi/Code/GitHub/PaperReadThrough/data/2501.04682v1/processed_content_list.json\"\n",
    "with open(pdf_json_rvsd_path, \"r\") as file:\n",
    "    pdf_json_rvsd = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name patterns for image / table / equation names\n",
    "IMG_REGX_NAME_PTRN = r\"(pic|picture|img|image|chart|figure|fig|table|tbl)\\s*([0-9]+(?:\\.[0-9]+)?|[0-9]+|[IVXLCDM]+|[a-zA-Z]+)\"\n",
    "TBL_REGX_NAME_PTRN = r\"(tbl|table|chart|figure|fig)\\s*([0-9]+(?:\\.[0-9]+)?|[0-9]+|[IVXLCDM]+|[a-zA-Z]+)\"\n",
    "EQT_REGX_NAME_PTRN = r\"(formula|equation|notation|syntax)\\s*([0-9]+(?:\\.[0-9]+)?|[0-9]+|[IVXLCDM]+|[a-zA-Z]+)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFSeg:\n",
    "    def __init__(self, pdf_json):\n",
    "        self.pdf_json = pdf_json\n",
    "\n",
    "    def get_toc_hierachy(self):\n",
    "        \"\"\"generate ToC tree\n",
    "        Args:\n",
    "            pdf_json:\n",
    "        Returns:\n",
    "            tree form hierachy of sections\n",
    "        \"\"\"\n",
    "        toc_hierachy = []\n",
    "        section_stack = []\n",
    "\n",
    "        for i, item in enumerate(self.pdf_json):\n",
    "            if item['type'] == 'title':\n",
    "                level = item['text_level']\n",
    "                title = item['text']\n",
    "\n",
    "                while section_stack and section_stack[-1]['level'] >= level:\n",
    "                    popped_section = section_stack.pop()\n",
    "                    popped_section['end_position'] = i - 1\n",
    "                    if section_stack:\n",
    "                        section_stack[-1]['subsection'].append(popped_section)\n",
    "                    else:\n",
    "                        toc_hierachy.append(popped_section)\n",
    "\n",
    "                new_section = {'title': title, 'level': level, 'start_position': i, 'end_position': -1, 'subsection': []}\n",
    "                section_stack.append(new_section)\n",
    "\n",
    "        while section_stack:\n",
    "            popped_section = section_stack.pop()\n",
    "            popped_section['end_position'] = len(self.pdf_json) - 1\n",
    "            if section_stack:\n",
    "                section_stack[-1]['subsection'].append(popped_section)\n",
    "            else:\n",
    "                toc_hierachy.append(popped_section)\n",
    "\n",
    "        return toc_hierachy\n",
    "    \n",
    "    def gen_seg_paras(self, toc_hierachy, seg_text_length:Optional[int]=20000):\n",
    "        \"\"\"segment content json based on toc hierachy\"\"\"\n",
    "        pdf_texts = [item.get('text', '') for item in self.pdf_json]\n",
    "\n",
    "        all_seg_paras = []\n",
    "        for section in toc_hierachy:\n",
    "            section_paras = []\n",
    "            \n",
    "            start_pos = section['start_position']\n",
    "            end_pos = section['end_position']\n",
    "            tmp_text = \"\\n\".join(pdf_texts[start_pos:end_pos+1])\n",
    "            \n",
    "            if len(tmp_text) > seg_text_length and section.get('subsection', []) != []:\n",
    "                # if the section is too long, then breakdown to subsection\n",
    "                for subsection in section.get('subsection'):\n",
    "                    sub_start_pos = subsection['start_position']\n",
    "                    sub_end_pos = subsection['end_position']\n",
    "                    section_paras.append(self.pdf_json[sub_start_pos:sub_end_pos+1])\n",
    "                    tmp_text = \"\\n\".join(pdf_texts[sub_start_pos:sub_end_pos+1])\n",
    "                    print('subsection', subsection.get('title'), len(tmp_text))\n",
    "            else:\n",
    "                section_paras.append(self.pdf_json[start_pos:end_pos+1])\n",
    "                print('section', section.get('title'), len(tmp_text))\n",
    "                    \n",
    "            all_seg_paras.extend(section_paras)\n",
    "        return all_seg_paras\n",
    "\n",
    "    def gen_md_from_json(self, content_json):\n",
    "        \"\"\"input json with predefined format and convert to markdown\"\"\"\n",
    "        md_text = \"\"\n",
    "        if len(content_json) > 0:\n",
    "            for item in content_json:\n",
    "                if item.get('type') == 'title':\n",
    "                    md_text += f\"{'#'*item.get('text_level')} {item.get('text')}  \\n\" \n",
    "\n",
    "                elif item.get('type') in ['image']:\n",
    "                    alt_text = \"\\n\".join(item.get('img_caption', [])) \n",
    "                    md_text += f\"\\n![{alt_text}]({item.get('img_path')} '{item.get('id')}')  \\n\"  \n",
    "                    md_text += \"\\n\".join(item.get('img_footnote'), []) \n",
    "\n",
    "                elif item.get('type') in ['table']:\n",
    "                    alt_text = \"\\n\".join(item.get('table_caption', [])) \n",
    "                    md_text += f\"\\n![{alt_text}]({item.get('img_path')} '{item.get('id')}')  \\n\"  \n",
    "                    md_text += \"\\n\".join(item.get('table_footnote'), []) \n",
    "\n",
    "                elif item.get('type') in ['equation']:\n",
    "                    md_text += f\"\"\"```latex\\n{item.get('text')}\\n```\"\"\"\n",
    "\n",
    "                elif item.get('type') in ['text', 'reference']:\n",
    "                    md_text += f\"{item.get('text')}  \\n\"  \n",
    "        return md_text\n",
    "    \n",
    "\n",
    "    def restore_seg_elements(self, seg_paras):\n",
    "        \"\"\"put all elements (images, tables, equations, refs) metioned in place where the refered to\"\"\"\n",
    "\n",
    "        img_lst = [x for x in self.pdf_json if x.get('type')=='image']\n",
    "        tbl_lst = [x for x in self.pdf_json if x.get('type')=='table']\n",
    "        eqt_lst = [x for x in self.pdf_json if x.get('type')=='equation']\n",
    "        ref_lst = [x for x in self.pdf_json if x.get('type')=='reference']\n",
    "\n",
    "        seg_paras_rvsd = []\n",
    "        for seg in seg_paras:\n",
    "            seg_img_lst = [x for x in seg if x.get('type')=='image']\n",
    "            seg_tbl_lst = [x for x in seg if x.get('type')=='table']\n",
    "            seg_eqt_lst = [x for x in seg if x.get('type')=='equation']\n",
    "            seg_ref_lst = [x for x in seg if x.get('type')=='reference']\n",
    "\n",
    "            for item in seg:\n",
    "                if item.get('if_being_reffered') is None:\n",
    "                    item_text = item.get('text', '')\n",
    "\n",
    "                    mtch_rslts = re.finditer(IMG_REGX_NAME_PTRN, item_text, re.IGNORECASE)\n",
    "                    for match in mtch_rslts:\n",
    "                        img_id = match.group(0)\n",
    "                        if img_id not in [x.get('id') for x in seg_img_lst]:\n",
    "                            added_items = [x for x in img_lst if x.get('id')==img_id]\n",
    "                            print(added_items)\n",
    "                            for y in added_items:\n",
    "                                y['if_being_reffered'] = True\n",
    "                            seg_img_lst.extend(added_items)\n",
    "                            seg.extend(added_items)\n",
    "\n",
    "                    mtch_rslts = re.finditer(TBL_REGX_NAME_PTRN, item_text, re.IGNORECASE)\n",
    "                    for match in mtch_rslts:\n",
    "                        tbl_id = match.group(0)\n",
    "                        if tbl_id not in [x.get('id') for x in seg_tbl_lst]:\n",
    "                            added_items = [x for x in tbl_lst if x.get('id')==tbl_id]\n",
    "                            for y in added_items:\n",
    "                                y['if_being_reffered'] = True\n",
    "                            seg_tbl_lst.extend(added_items)\n",
    "                            seg.extend(added_items)\n",
    "\n",
    "                    mtch_rslts = re.finditer(EQT_REGX_NAME_PTRN, item_text, re.IGNORECASE)\n",
    "                    for match in mtch_rslts:\n",
    "                        eqt_id = match.group(0)\n",
    "                        if eqt_id not in [x.get('id') for x in seg_eqt_lst]:\n",
    "                            added_items = [x for x in eqt_lst if x.get('id')==eqt_id]\n",
    "                            for y in added_items:\n",
    "                                y['if_being_reffered'] = True\n",
    "                            seg_eqt_lst.extend(added_items)\n",
    "                            seg.extend(added_items)\n",
    "            seg_paras_rvsd.append(seg)\n",
    "        \n",
    "        return seg_paras_rvsd\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = PDFSeg(pdf_json_rvsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_hierachy = seg.get_toc_hierachy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': '1. Introduction ',\n",
       "  'level': 1,\n",
       "  'start_position': 18,\n",
       "  'end_position': 55,\n",
       "  'subsection': [{'title': '1.1. Motivation ',\n",
       "    'level': 2,\n",
       "    'start_position': 19,\n",
       "    'end_position': 51,\n",
       "    'subsection': []},\n",
       "   {'title': '1.2. Outline ',\n",
       "    'level': 2,\n",
       "    'start_position': 52,\n",
       "    'end_position': 55,\n",
       "    'subsection': []}]},\n",
       " {'title': '2. Meta Chain-Of-Thought ',\n",
       "  'level': 1,\n",
       "  'start_position': 56,\n",
       "  'end_position': 79,\n",
       "  'subsection': [{'title': '2.1. Deriving The Meta-CoT Process ',\n",
       "    'level': 2,\n",
       "    'start_position': 58,\n",
       "    'end_position': 73,\n",
       "    'subsection': []},\n",
       "   {'title': '2.2. Why Does (Classical) CoT Fail? ',\n",
       "    'level': 2,\n",
       "    'start_position': 74,\n",
       "    'end_position': 79,\n",
       "    'subsection': []}]},\n",
       " {'title': '3. Towards Deliberate Reasoning With Language Models - Search ',\n",
       "  'level': 1,\n",
       "  'start_position': 80,\n",
       "  'end_position': 117,\n",
       "  'subsection': [{'title': '3.1. Inference-Time Compute: Search ',\n",
       "    'level': 2,\n",
       "    'start_position': 86,\n",
       "    'end_position': 91,\n",
       "    'subsection': []},\n",
       "   {'title': '3.2. Inference-Time Compute: Verifcation ',\n",
       "    'level': 2,\n",
       "    'start_position': 92,\n",
       "    'end_position': 98,\n",
       "    'subsection': []},\n",
       "   {'title': '3.3. From Best-of-N To General Search ',\n",
       "    'level': 2,\n",
       "    'start_position': 99,\n",
       "    'end_position': 109,\n",
       "    'subsection': []},\n",
       "   {'title': '3.4. Is Search (Inference Time Compute) A Fundamental Capability Shift? ',\n",
       "    'level': 2,\n",
       "    'start_position': 110,\n",
       "    'end_position': 117,\n",
       "    'subsection': []}]},\n",
       " {'title': '4. Towards Meta-CoT Reasoning ',\n",
       "  'level': 1,\n",
       "  'start_position': 118,\n",
       "  'end_position': 194,\n",
       "  'subsection': [{'title': '4.1. Bootstrapping Meta-CoT ',\n",
       "    'level': 2,\n",
       "    'start_position': 122,\n",
       "    'end_position': 132,\n",
       "    'subsection': [{'title': '4.1.1. Self-Taught Reasoner ',\n",
       "      'level': 3,\n",
       "      'start_position': 124,\n",
       "      'end_position': 128,\n",
       "      'subsection': []},\n",
       "     {'title': '4.1.2. Meta-STaR ',\n",
       "      'level': 3,\n",
       "      'start_position': 129,\n",
       "      'end_position': 132,\n",
       "      'subsection': []}]},\n",
       "   {'title': '4.2. Empirical Examples Of Internalizing Search ',\n",
       "    'level': 2,\n",
       "    'start_position': 133,\n",
       "    'end_position': 168,\n",
       "    'subsection': [{'title': '4.2.1. Small-Scale Empirical Results on Internalizing Search ',\n",
       "      'level': 3,\n",
       "      'start_position': 135,\n",
       "      'end_position': 142,\n",
       "      'subsection': []},\n",
       "     {'title': '4.2.2. In-context Exploration For LLMs ',\n",
       "      'level': 3,\n",
       "      'start_position': 143,\n",
       "      'end_position': 150,\n",
       "      'subsection': []},\n",
       "     {'title': '4.2.3. Using variable Compute ',\n",
       "      'level': 3,\n",
       "      'start_position': 151,\n",
       "      'end_position': 157,\n",
       "      'subsection': []},\n",
       "     {'title': '4.2.4. Backtracking in LLMs ',\n",
       "      'level': 3,\n",
       "      'start_position': 158,\n",
       "      'end_position': 168,\n",
       "      'subsection': []}]},\n",
       "   {'title': '4.3. Synthetic Meta-CoT Via Search ',\n",
       "    'level': 2,\n",
       "    'start_position': 169,\n",
       "    'end_position': 182,\n",
       "    'subsection': [{'title': '4.3.1. Monte-Carlo Tree Search ',\n",
       "      'level': 3,\n",
       "      'start_position': 175,\n",
       "      'end_position': 179,\n",
       "      'subsection': []},\n",
       "     {'title': '4.3.2. $A^{*}$ search ',\n",
       "      'level': 3,\n",
       "      'start_position': 180,\n",
       "      'end_position': 182,\n",
       "      'subsection': []}]},\n",
       "   {'title': '4.4. Do Advanced Reasoning Systems Implement In-Context Search? ',\n",
       "    'level': 2,\n",
       "    'start_position': 183,\n",
       "    'end_position': 194,\n",
       "    'subsection': []}]},\n",
       " {'title': '5. Process Supervision ',\n",
       "  'level': 1,\n",
       "  'start_position': 195,\n",
       "  'end_position': 205,\n",
       "  'subsection': [{'title': '5.1. Learning Process Reward Models ',\n",
       "    'level': 2,\n",
       "    'start_position': 197,\n",
       "    'end_position': 198,\n",
       "    'subsection': []},\n",
       "   {'title': '5.2. PRM Quality And Its Efect On Search ',\n",
       "    'level': 2,\n",
       "    'start_position': 199,\n",
       "    'end_position': 202,\n",
       "    'subsection': []},\n",
       "   {'title': '5.3. Verifable Versus Open-Ended Problems ',\n",
       "    'level': 2,\n",
       "    'start_position': 203,\n",
       "    'end_position': 205,\n",
       "    'subsection': []}]},\n",
       " {'title': '6. Meta Reinforcement Learning - Learning How To Think ',\n",
       "  'level': 1,\n",
       "  'start_position': 206,\n",
       "  'end_position': 263,\n",
       "  'subsection': [{'title': '6.1. Meta-RL In Small Domains ',\n",
       "    'level': 2,\n",
       "    'start_position': 229,\n",
       "    'end_position': 232,\n",
       "    'subsection': []},\n",
       "   {'title': '6.2. Meta-RL In Language Model Reasoning ',\n",
       "    'level': 2,\n",
       "    'start_position': 233,\n",
       "    'end_position': 240,\n",
       "    'subsection': []},\n",
       "   {'title': '6.3. Efciency Or Super-Intelligence? ',\n",
       "    'level': 2,\n",
       "    'start_position': 241,\n",
       "    'end_position': 248,\n",
       "    'subsection': []},\n",
       "   {'title': '6.4. Can System 2 Reasoning Emerge From Pure RL? ',\n",
       "    'level': 2,\n",
       "    'start_position': 249,\n",
       "    'end_position': 263,\n",
       "    'subsection': [{'title': '6.4.1. Inducing Meta-Reasoning In LLMs ',\n",
       "      'level': 3,\n",
       "      'start_position': 252,\n",
       "      'end_position': 263,\n",
       "      'subsection': []}]}]},\n",
       " {'title': '7. Putting It All Together - A Pipeline for System 2 Reasoning ',\n",
       "  'level': 1,\n",
       "  'start_position': 264,\n",
       "  'end_position': 296,\n",
       "  'subsection': [{'title': '7.1. Instruction Tuning ',\n",
       "    'level': 2,\n",
       "    'start_position': 266,\n",
       "    'end_position': 267,\n",
       "    'subsection': []},\n",
       "   {'title': '7.2. Post-Training With RL ',\n",
       "    'level': 2,\n",
       "    'start_position': 268,\n",
       "    'end_position': 296,\n",
       "    'subsection': [{'title': '7.2.2. Discount Rates ',\n",
       "      'level': 3,\n",
       "      'start_position': 289,\n",
       "      'end_position': 296,\n",
       "      'subsection': []}]}]},\n",
       " {'title': '8. Going Forward ',\n",
       "  'level': 1,\n",
       "  'start_position': 297,\n",
       "  'end_position': 349,\n",
       "  'subsection': [{'title': '8.1. The \"Big MATH\" Project ',\n",
       "    'level': 2,\n",
       "    'start_position': 301,\n",
       "    'end_position': 318,\n",
       "    'subsection': [{'title': '8.1.1. Data Sourcing ',\n",
       "      'level': 3,\n",
       "      'start_position': 310,\n",
       "      'end_position': 312,\n",
       "      'subsection': []},\n",
       "     {'title': '8.1.2. Data Filtering ',\n",
       "      'level': 3,\n",
       "      'start_position': 313,\n",
       "      'end_position': 318,\n",
       "      'subsection': []}]},\n",
       "   {'title': '8.2. Infrastructure ',\n",
       "    'level': 2,\n",
       "    'start_position': 319,\n",
       "    'end_position': 325,\n",
       "    'subsection': []},\n",
       "   {'title': '8.3. Open Research Questions ',\n",
       "    'level': 2,\n",
       "    'start_position': 326,\n",
       "    'end_position': 349,\n",
       "    'subsection': [{'title': '8.3.1. Open-Ended Verifcation And CoT Faithfulness ',\n",
       "      'level': 3,\n",
       "      'start_position': 328,\n",
       "      'end_position': 331,\n",
       "      'subsection': []},\n",
       "     {'title': '8.3.2. Process Guidance And The Verifer Gap ',\n",
       "      'level': 3,\n",
       "      'start_position': 332,\n",
       "      'end_position': 334,\n",
       "      'subsection': []},\n",
       "     {'title': '8.3.3. Scaling Laws For Reasoning And Search ',\n",
       "      'level': 3,\n",
       "      'start_position': 335,\n",
       "      'end_position': 337,\n",
       "      'subsection': []},\n",
       "     {'title': '8.3.4. Meta-Search/Search 2 ',\n",
       "      'level': 3,\n",
       "      'start_position': 338,\n",
       "      'end_position': 342,\n",
       "      'subsection': []},\n",
       "     {'title': '8.3.5. Reasoning with External Tools ',\n",
       "      'level': 3,\n",
       "      'start_position': 343,\n",
       "      'end_position': 349,\n",
       "      'subsection': []}]}]},\n",
       " {'title': '9. Conclusion ',\n",
       "  'level': 1,\n",
       "  'start_position': 350,\n",
       "  'end_position': 353,\n",
       "  'subsection': []},\n",
       " {'title': '10. Acknowledgments ',\n",
       "  'level': 1,\n",
       "  'start_position': 354,\n",
       "  'end_position': 355,\n",
       "  'subsection': []},\n",
       " {'title': 'References ',\n",
       "  'level': 1,\n",
       "  'start_position': 356,\n",
       "  'end_position': 413,\n",
       "  'subsection': []},\n",
       " {'title': 'A. Prompting ',\n",
       "  'level': 1,\n",
       "  'start_position': 414,\n",
       "  'end_position': 417,\n",
       "  'subsection': []},\n",
       " {'title': 'B. Regret Analysis ',\n",
       "  'level': 1,\n",
       "  'start_position': 418,\n",
       "  'end_position': 419,\n",
       "  'subsection': []},\n",
       " {'title': 'C. Diferent Instruction Tuning Objectives ',\n",
       "  'level': 1,\n",
       "  'start_position': 420,\n",
       "  'end_position': 430,\n",
       "  'subsection': []},\n",
       " {'title': 'D. MCTS Details ',\n",
       "  'level': 1,\n",
       "  'start_position': 431,\n",
       "  'end_position': 440,\n",
       "  'subsection': []},\n",
       " {'title': 'E. Chains-Of-Thought ',\n",
       "  'level': 1,\n",
       "  'start_position': 441,\n",
       "  'end_position': 643,\n",
       "  'subsection': []}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toc_hierachy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "section 1. Introduction  6335\n",
      "section 2. Meta Chain-Of-Thought  10669\n",
      "section 3. Towards Deliberate Reasoning With Language Models - Search  13821\n",
      "subsection 4.1. Bootstrapping Meta-CoT  3760\n",
      "subsection 4.2. Empirical Examples Of Internalizing Search  13436\n",
      "subsection 4.3. Synthetic Meta-CoT Via Search  4532\n",
      "subsection 4.4. Do Advanced Reasoning Systems Implement In-Context Search?  4534\n",
      "section 5. Process Supervision  6885\n",
      "subsection 6.1. Meta-RL In Small Domains  1275\n",
      "subsection 6.2. Meta-RL In Language Model Reasoning  2672\n",
      "subsection 6.3. Efciency Or Super-Intelligence?  3958\n",
      "subsection 6.4. Can System 2 Reasoning Emerge From Pure RL?  9318\n",
      "section 7. Putting It All Together - A Pipeline for System 2 Reasoning  15162\n",
      "subsection 8.1. The \"Big MATH\" Project  10507\n",
      "subsection 8.2. Infrastructure  2648\n",
      "subsection 8.3. Open Research Questions  11793\n",
      "section 9. Conclusion  1745\n",
      "section 10. Acknowledgments  197\n",
      "section References  32378\n",
      "section A. Prompting  711\n",
      "section B. Regret Analysis  257\n",
      "section C. Diferent Instruction Tuning Objectives  2665\n",
      "section D. MCTS Details  2937\n",
      "section E. Chains-Of-Thought  64521\n"
     ]
    }
   ],
   "source": [
    "seg_paras = seg.gen_seg_paras(toc_hierachy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[{'type': 'image', 'img_path': 'images/c9d400a79bd62951a363cac2aabd041f71ae1d695b6a98d1affe998739c86cb1.jpg', 'img_caption': ['Figure 1: Top: Performance of current frontier models by size on the HARP mathematics benchmark (Yue et al., 2024) by difculty level and topic. The OpenAI O1 series signifcantly out-performs prior generation models across the board. Source: Figure 3 in (Yue et al., 2024). Bottom Average number of tokens generated by each model grouped by difculty level, as well as average number of tokens in human-generated solutions (using GPT4 tokenizer). Source: Figure 4 in (Yue et al., 2024). '], 'img_footnote': [], 'page_idx': 7, 'id': 'Figure 1', 'related_ids': ['Figure 3', 'Figure 4'], 'if_aligned': True}]\n",
      "[]\n",
      "[{'type': 'image', 'img_path': 'images/98af3e8774697add630cde871085b466600f00539cd676efc56ec7b6e7631f9c.jpg', 'img_caption': ['Figure 13: Resulting $\\\\mathbf{A}^{*}$ search tree on the math problem from OpenAI (2024). This trace presents more of a best-frst approach with fewer backtracks, concentrated around key steps, as compared to the one produced by MCTS in Figure 12. '], 'img_footnote': [], 'page_idx': 22, 'id': 'Figure 13', 'related_ids': ['Figure 12'], 'if_aligned': True}]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[{'type': 'image', 'img_path': 'images/8c989d4b2b9ea1eb55971eb6812c88935953c1ef2e8d66451b9faf96f5219c79.jpg', 'img_caption': ['Figure 17: Left: Scaling curves for Best-of-N (BoN) using PRMs trained with diferent number of questions with oracle and majority vote. Right: Beam search $\\\\mathrm{N}{=}5$ , beam width $=4$ ) accuracy and number of tokens used during search with the same PRMs. With more training data, the PRM’s ability to verify at outcome-level and process-level improves. '], 'img_footnote': [], 'page_idx': 28, 'id': 'Figure 17', 'related_ids': [], 'if_aligned': True}]\n",
      "[{'type': 'image', 'img_path': 'images/6c9177669d0ef88466bdb872144cb9a411626a12e1f505dcd53cfed30fa735cc.jpg', 'img_caption': ['Figure 20: The benefts of reinforcement learning for langauge model reasoning. When comparing Expert Iteration $(\\\\mathrm{SoS}\\\\!+\\\\!\\\\mathrm{STaR})$ vs. the RL-based $\\\\mathrm{SoS+APA}_{\\\\mathrm{}}$ , we see that the use of RL leads to improved policy performance (left), with fewer arithmetic errors (center), and improved efciency (right). Source: (left to right) Figures 4a, 6a, and 6b from (Gandhi et al., 2024). '], 'img_footnote': [], 'page_idx': 30, 'id': 'Figure 20', 'related_ids': ['Figures'], 'if_aligned': True}]\n",
      "[]\n",
      "[]\n",
      "[{'type': 'image', 'img_path': 'images/6a39a587fa7886e943f5ea863b19fbaba78aed8e33ad3c92f1a043a18e4269e6.jpg', 'img_caption': ['Figure 21: Overview of Reinforcement Learning with Execution Feedback. This training routine directly maps to the E-RL2 framework (Stadie et al., 2019). Source: Figure 2 in (Gehring et al., 2024). '], 'img_footnote': [], 'page_idx': 31, 'id': 'Figure 21', 'related_ids': ['Figure 2'], 'if_aligned': True}]\n",
      "[]\n",
      "[{'type': 'image', 'img_path': 'images/6c9177669d0ef88466bdb872144cb9a411626a12e1f505dcd53cfed30fa735cc.jpg', 'img_caption': ['Figure 20: The benefts of reinforcement learning for langauge model reasoning. When comparing Expert Iteration $(\\\\mathrm{SoS}\\\\!+\\\\!\\\\mathrm{STaR})$ vs. the RL-based $\\\\mathrm{SoS+APA}_{\\\\mathrm{}}$ , we see that the use of RL leads to improved policy performance (left), with fewer arithmetic errors (center), and improved efciency (right). Source: (left to right) Figures 4a, 6a, and 6b from (Gandhi et al., 2024). '], 'img_footnote': [], 'page_idx': 30, 'id': 'Figure 20', 'related_ids': ['Figures'], 'if_aligned': True, 'if_being_reffered': True}]\n",
      "[]\n",
      "[{'type': 'image', 'img_path': 'images/611e5d526b2d832a8cf0d8a5762f16cb5baba521e529f9ff53b140024c141596.jpg', 'img_caption': ['Figure 22: Scaling results for Reinforcement Learning with Execution Feedback. Left: Pass $@1$ and pass $@10$ for 8 and 70B models when given either ground truth feedback or random execution feedback. Right: Model solve rates at various turn limits (1, 3, 5, and 10) and sample budgets. Source: Figure 4 in (Gehring et al., 2024). '], 'img_footnote': [], 'page_idx': 32, 'id': 'Figure 22', 'related_ids': ['Figure 4'], 'if_aligned': True}]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[{'type': 'image', 'img_path': 'images/1b26d4f624508324ccfb855c6718b15c6633e921b1cac96e6dd6aec78f538530.jpg', 'img_caption': ['Figure 9: Inference compute scaling relationships for the o1 model (Left, sourced from (OpenAI, 2024) on AIME, Stream-of-Search on the Game of 24 (Middle) and MAV-MCTS on Chess (Right, sourced from (Schultz et al., 2024)). These fgures show performance of a single model under diferent token sampling budgets. '], 'img_footnote': [], 'page_idx': 17, 'id': 'Figure 9', 'related_ids': [], 'if_aligned': True}]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[{'type': 'image', 'img_path': 'images/8cc13ba40376bdede242a8bbb1e64189ca212f1f0fff2e17d16625a0f5926730.jpg', 'img_caption': ['Figure 3: Scaling trends for verifer models on algorithmic reasoning, grade-school math (GSM8k), and transfer from GSM8k to MATH. The performance of all verifers improves in the best-of-N setting, as N increases. Figure sourced from (Zhang et al., 2024a). '], 'img_footnote': [], 'page_idx': 10, 'id': 'Figure 3', 'related_ids': ['Figure sourced'], 'if_aligned': True}]\n",
      "[{'type': 'image', 'img_path': 'images/611e5d526b2d832a8cf0d8a5762f16cb5baba521e529f9ff53b140024c141596.jpg', 'img_caption': ['Figure 22: Scaling results for Reinforcement Learning with Execution Feedback. Left: Pass $@1$ and pass $@10$ for 8 and 70B models when given either ground truth feedback or random execution feedback. Right: Model solve rates at various turn limits (1, 3, 5, and 10) and sample budgets. Source: Figure 4 in (Gehring et al., 2024). '], 'img_footnote': [], 'page_idx': 32, 'id': 'Figure 22', 'related_ids': ['Figure 4'], 'if_aligned': True, 'if_being_reffered': True}]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "seg_paras_rvsd = seg.restore_seg_elements(seg_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_text = seg.gen_md_from_json(pdf_json_rvsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4fun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
