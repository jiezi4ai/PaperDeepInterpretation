{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"From Few to Many: Self-Improving Many-Shot Reasoners Through Iterative Optimization and Generation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Metadata Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 获取当前脚本所在目录的父目录 (即 my_project)\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# 将父目录添加到 sys.path\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apis.arxiv_tool import ArxivKit\n",
    "from apis.semanticscholar_tool import SemanticScholarKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv = ArxivKit()\n",
    "arxiv_metadata_lst = arxiv.retrieve_metadata_by_paper(query_term=title, max_cnt=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_metadata_lst[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SemanticScholarKit()\n",
    "ss_metadata_lst = ss.search_paper_by_keywords(query=title, limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_metadata_lst[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_ss_id = ss_metadata_lst[0].get('paperId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations & References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_metadata_lst = ss.get_semanticscholar_references(paper_id='603bb1eb011147bed0766c0b0c0bf4bb83ef4b9a', limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citedby_metadata_lst = ss.get_semanticscholar_citedby(paper_id='603bb1eb011147bed0766c0b0c0bf4bb83ef4b9a', limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citedby_metadata_lst[0].__dict__.get('_data').keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommended Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_papers_lst = ss.find_recommendations(positive_paper_ids=[paper_ss_id], limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(recommended_papers_lst[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Categories, Keywords and Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def upload_file(api_key, file_path):\n",
    "        # filename = os.path.splitext(os.path.basename(file_path))[0].lower()\n",
    "        myfile = genai.upload_file(path=file_path)\n",
    "        return myfile.name  # \"files/*\"\n",
    "\n",
    "    def gemini_remove_file(api_key, filename):\n",
    "        genai.configure(api_key=api_key)\n",
    "        if not filename.startswith(\"files/\"):\n",
    "            filename = f\"files/{filename}\"\n",
    "\n",
    "        all_files = genai.list_files()\n",
    "        if filename in all_files:\n",
    "            genai.delete_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def gemini_llm_w_files(api_key, model_name, prompt, filenames):\n",
    "        genai.configure(api_key=api_key)\n",
    "        all_files = genai.list_files()\n",
    "        valid_filenames = []\n",
    "        for filename in filenames:\n",
    "            if not filename.startswith(\"files/\"):\n",
    "                filename = f\"files/{filename}\"\n",
    "            if filename in all_files:\n",
    "                valid_filenames.append(filename)\n",
    "        model = genai.GenerativeModel(api_key=api_key, model_name=model_name)\n",
    "        response = model.generate_content([prompt] + valid_filenames)\n",
    "        return (response.text)\n",
    "\n",
    "\n",
    "    def gemini_llm(self, api_key, model_name, prompt, if_json=False, response_class=None, file_paths=None, image_paths=None):\n",
    "        genai.configure(api_key=api_key)\n",
    "        model = genai.GenerativeModel(model_name=model_name)\n",
    "        \n",
    "        # set up parameters\n",
    "        # output format\n",
    "        if if_json:\n",
    "            response_mime_type = \"application/json\"\n",
    "        else:\n",
    "            response_mime_type = \"text/plain\"\n",
    "        # output schema\n",
    "        if response_class:\n",
    "            response_scheme = list[response_class]\n",
    "        else:\n",
    "            response_scheme = None\n",
    "\n",
    "        # generation with files\n",
    "        if file_paths:\n",
    "            # check if local file or file that uploaded\n",
    "            filenms = []\n",
    "            for file in file_paths:\n",
    "                myfile = genai.upload_file(path=file)\n",
    "                filenms.append(myfile.name)\n",
    "            contents = [prompt] + filenms\n",
    "        \n",
    "        # generation with images\n",
    "        if image_paths:\n",
    "            images= []\n",
    "            # check if local file or file that uploaded\n",
    "            for image in image_paths:\n",
    "                images.append(img.open(image))\n",
    "            contents = [prompt] + images\n",
    "\n",
    "        model_config = genai.GenerationConfig(\n",
    "                response_mime_type=response_mime_type, response_schema=response_scheme\n",
    "            )\n",
    "\n",
    "        result = model.generate_content(\n",
    "            contents=contents,\n",
    "            generation_config=model_config,\n",
    "        )\n",
    "        print(result) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jiezi4ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
