{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"Training Large Language Models to Reason in a Continuous Latent Space\", \n",
    "          \"Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Thought\",\n",
    "          \"s1: Simple test-time scaling\",\n",
    "          \"From Few to Many: Self-Improving Many-Shot Reasoners Through Iterative Optimization and Generation\",\n",
    "          \"Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search\"]\n",
    "\n",
    "\n",
    "pdf_pathes = [\"./data/2412.06769v2.pdf\",\n",
    "              \"./data/2501.04682v1.pdf\",\n",
    "              \"./data/2501.19393v2.pdf\",\n",
    "              \"./data/2502.00330v1.pdf\",\n",
    "              \"./data/2502.02508v1.pdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 获取当前脚本所在目录的父目录 (即 my_project)\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# 将父目录添加到 sys.path\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "from typing import List, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, filename):\n",
    "    \"\"\"Downloads a file from the given URL and saves it as filename.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        print(f\"Successfully downloaded: {filename}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def unzip_file(original_zip_file, destination_folder):\n",
    "    assert os.path.splitext(original_zip_file)[-1] == '.zip'\n",
    "    with zipfile.ZipFile(original_zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(destination_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apis.arxiv_tool import ArxivKit\n",
    "from apis.semanticscholar_tool import SemanticScholarKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv = ArxivKit()\n",
    "\n",
    "arxiv_metadata = []\n",
    "for title in titles:\n",
    "    candit_arxiv_metadata = arxiv.retrieve_metadata_by_paper(query_term=title, max_cnt=3)\n",
    "    arxiv_metadata.append(candit_arxiv_metadata)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SemanticScholarKit()\n",
    "\n",
    "ss_metadata = []\n",
    "for title in titles:\n",
    "    candit_ss_metadata = ss.search_paper_by_keywords(query=title, limit=3)\n",
    "    ss_metadata.append(candit_ss_metadata)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference and Citedby Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_ss_id = ss_metadata[0][0].get('paperId')\n",
    "print(paper_ss_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_metadata = ss.get_semanticscholar_references(paper_id=paper_ss_id, limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reference_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citedby_metadata = ss.get_semanticscholar_citedby(paper_id=paper_ss_id, limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(citedby_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Structural Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "\n",
    "def pdf_outline_detection(pdf_path, excpert_len:Optional[int]=300):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    toc_infos = doc.get_toc(simple=False) or []\n",
    "\n",
    "    pdf_toc = []\n",
    "    for item in toc_infos:\n",
    "        lvl = item[0] if len(item) > 0 else None\n",
    "        title = item[1] if len(item) > 1 else None\n",
    "        start_page = item[2] if len(item) > 2 else None\n",
    "        end_pos = item[3].get('to') if len(item) > 3 and item[3] else None\n",
    "        nameddest = item[3].get('nameddest') if len(item) > 3 and item[3] else None\n",
    "        if_collapse = item[3].get('collapse', False) if len(item) > 3 and item[3] else None\n",
    "\n",
    "        if start_page is not None:\n",
    "            page = doc[start_page-1]\n",
    "            blocks = page.get_text(\"blocks\")\n",
    "\n",
    "            lines = \"\"\n",
    "            for block in blocks:\n",
    "                x0, y0, x1, y1, text, _, _ = block\n",
    "                if len(lines) < excpert_len:\n",
    "                    if end_pos and x0 >= end_pos[0]:\n",
    "                        lines += text\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            pdf_toc.append({\n",
    "                \"level\": lvl,\n",
    "                \"title\": title,\n",
    "                \"page\": start_page,\n",
    "                \"position\": end_pos,\n",
    "                \"nameddest\": nameddest,\n",
    "                'if_collapse': if_collapse,\n",
    "                \"excerpt\": lines + \"...\"\n",
    "            })\n",
    "    return pdf_toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"/home/jiezi/Code/Temp/data/2412.06769v2.pdf\"\n",
    "pdf_toc = pdf_outline_detection(pdf_path=pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miner U PDF Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apis.mineru_tool import MinerUKit\n",
    "\n",
    "mineru_api_key = os.getenv('MINERU_API_KEY_1')\n",
    "mineru = MinerUKit(api_key=mineru_api_key)\n",
    "upload_res = mineru.batch_process_files(pdf_files=pdf_pathes, if_ocr=False, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id = upload_res.json().get('data', {}).get('batch_id')\n",
    "running_res = mineru.batch_status_check(batch_id=batch_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path = \"/home/jiezi/Code/Temp/tmp\"\n",
    "\n",
    "if running_res.json().get('msg') == 'ok':\n",
    "    results = running_res.json().get('data', {}).get('extract_result', []) \n",
    "    for item in results:\n",
    "        if item.get('state') == 'done':\n",
    "            file_name_nosuffix = item.get('file_name').rsplit('.', 1)[0] \n",
    "            zip_url = item.get('full_zip_url')\n",
    "            download_file_name = os.path.join(temp_path, file_name_nosuffix+\".zip\") \n",
    "            unzip_folder_name = os.path.join(temp_path, file_name_nosuffix) \n",
    "            download_file(zip_url, download_file_name)\n",
    "            unzip_file(download_file_name, unzip_folder_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "temp_path = \"/home/jiezi/Code/Temp/tmp\"\n",
    "file_name_nosuffix = \"2412.06769v2\"\n",
    "file_path = os.path.join(temp_path, file_name_nosuffix)\n",
    "\n",
    "from pathlib import Path  \n",
    " \n",
    "for file in Path(file_path).glob('*'): \n",
    "    file_nm = os.path.basename(file)\n",
    "    if \"_origin.pdf\" in file_nm:\n",
    "        os.remove(file) \n",
    "    elif \"_content_list.json\" in file_nm:\n",
    "        os.rename(file, os.path.join(file_path, \"content_list.json\"))\n",
    "\n",
    "md_file = os.path.join(file_path, \"full.md\")\n",
    "content_json_file = os.path.join(file_path, \"content_list.json\")\n",
    "layout_json_file = os.path.join(file_path, \"layout.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/home/jiezi/Code/Temp/tmp/2412.06769v2/content_list.json\") as json_data:\n",
    "    content_json = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_file = \"/home/jiezi/Code/Temp/tmp/2412.06769v2/full.md\"\n",
    "with open(md_file, 'r', encoding='utf-8') as f:\n",
    "    markdown_content = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown Table Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covert table from Markdown syntax to html form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def markdown_table_to_html(markdown_text):\n",
    "    \"\"\"\n",
    "    将 Markdown 文本中的 Markdown 表格转换为 HTML 表格。\n",
    "\n",
    "    Args:\n",
    "        markdown_text: 包含 Markdown 表格的 Markdown 文本。\n",
    "\n",
    "    Returns:\n",
    "        转换后的 Markdown 文本，表格部分已转换为 HTML 表格。\n",
    "    \"\"\"\n",
    "\n",
    "    lines = markdown_text.splitlines()\n",
    "    output_lines = []\n",
    "    in_table = False\n",
    "    table_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.strip().startswith('|'):\n",
    "            in_table = True\n",
    "            table_lines.append(line)\n",
    "        else:\n",
    "            if in_table:\n",
    "                # 表格结束，处理之前收集的表格行\n",
    "                html_table = _convert_table_lines_to_html(table_lines)\n",
    "                output_lines.append(html_table)\n",
    "                in_table = False\n",
    "                table_lines = []\n",
    "            output_lines.append(line)\n",
    "\n",
    "    # 处理文本末尾可能存在的表格\n",
    "    if in_table:\n",
    "        html_table = _convert_table_lines_to_html(table_lines)\n",
    "        output_lines.append(html_table)\n",
    "\n",
    "    return \"\\n\".join(output_lines)\n",
    "\n",
    "\n",
    "def _convert_table_lines_to_html(table_lines):\n",
    "    \"\"\"\n",
    "    将 Markdown 表格行转换为 HTML 表格。\n",
    "\n",
    "    Args:\n",
    "        table_lines: Markdown 表格行的列表。\n",
    "\n",
    "    Returns:\n",
    "        HTML 表格字符串。\n",
    "    \"\"\"\n",
    "    html_lines = [\"<table>\", \"  <thead>\", \"    <tr>\"]\n",
    "    header_cells = [cell.strip() for cell in table_lines[0].strip('|').split('|')]\n",
    "    for header in header_cells:\n",
    "        html_lines.append(f\"      <th>{header}</th>\")\n",
    "    html_lines.append(\"    </tr>\")\n",
    "    html_lines.append(\"  </thead>\")\n",
    "    html_lines.append(\"  <tbody>\")\n",
    "\n",
    "    if len(table_lines) > 1 and re.match(r'^\\|[-:| ]+\\|[-:| ]*$', table_lines[1].strip()):\n",
    "        # 存在分隔行，跳过分隔行，从第三行开始是数据行\n",
    "        data_start_index = 2\n",
    "    else:\n",
    "        data_start_index = 1 # 没有分隔行，从第二行开始是数据行\n",
    "\n",
    "    for i in range(data_start_index, len(table_lines)):\n",
    "        html_lines.append(\"    <tr>\")\n",
    "        data_cells = [cell.strip() for cell in table_lines[i].strip('|').split('|')]\n",
    "        for cell in data_cells:\n",
    "            html_lines.append(f\"      <td>{cell}</td>\")\n",
    "        html_lines.append(\"    </tr>\")\n",
    "\n",
    "    html_lines.append(\"  </tbody>\")\n",
    "    html_lines.append(\"</table>\")\n",
    "    return \"\\n\".join(html_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_content = markdown_table_to_html(markdown_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align Markdown Titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Align markdown title with pdf ToC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def restore_md_toc(md_content, pdf_toc):\n",
    "    \"\"\"\n",
    "    Align markdown title with pdf table of content (generated from fitz)\n",
    "\n",
    "    Args:\n",
    "        md_file: Path to the markdown file.\n",
    "        pdf_toc: pdf toc from pdf_outline_detection function\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries, where each dictionary represents a section\n",
    "        with 'level', 'section_num', 'title', and 'text' keys.\n",
    "        Returns an empty list if the file doesn't exist.\n",
    "        Returns None if an error occurs.\n",
    "    \"\"\"\n",
    "    if pdf_toc:\n",
    "        modified_lines = []  # 用于存储修改后的行的列表\n",
    "\n",
    "        title_pattern = r\"^#{1,}\\s*.*$\"  # patttern of markdown title\n",
    "        md_titles = []\n",
    "\n",
    "        for idx, line in enumerate(md_content.splitlines()):  # iterate markdown lines\n",
    "            if line.strip() not in [\"\\n\", \"\\s\", \"\\r\", \"\"]:\n",
    "                match = re.search(title_pattern, line)\n",
    "                if match:  # find markdown title\n",
    "                    sec_title = line\n",
    "                    flag = 0\n",
    "\n",
    "                    for x in pdf_toc:  # iterate pdf toc, refine markdown title based on toc title\n",
    "                        toc_title = x['title'] \n",
    "                        toc_level = int(x['level'])  \n",
    "                        if toc_title in line:  \n",
    "                            sec_title = \"#\"*toc_level + \" \" + toc_title + \"  \"\n",
    "                            flag = 1\n",
    "                            break\n",
    "                    \n",
    "                    if flag == 0:  # markdown title not exit in toc\n",
    "                        for item in ['Acknowledgement', 'Reference', 'Appendix']:\n",
    "                            if item in line:\n",
    "                                sec_title = line\n",
    "                                flag = 1\n",
    "                    \n",
    "                    if flag == 0:\n",
    "                        if len(md_titles) > 0:\n",
    "                            if re.match('^#{1,}', md_titles[-1]):\n",
    "                                pre_level = re.match('^#{1,}', md_titles[-1]).group(0) + \"#\"\n",
    "                                sec_title = re.sub('^#{1,}', pre_level, line)\n",
    "                            else:\n",
    "                                sec_title = \"#\" + line\n",
    "\n",
    "                    modified_lines.append(sec_title)\n",
    "                    md_titles.append(sec_title)  # get markdown title\n",
    "\n",
    "                else:\n",
    "                    modified_lines.append(line)\n",
    "    return \"\\n\".join(modified_lines), md_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_content_rvsd, md_titles = restore_md_toc(markdown_content, pdf_toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Json Content (Charts, Tables, and Equations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get id, title, desc, etc. for charts, tables, and equations in content json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_lines(text, sentence_length):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    # 使用正则表达式分割句子\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|;|!)\\s', text) # 更精确的断句正则\n",
    "\n",
    "    result = \"\"\n",
    "    current_length = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        cleaned_sentence = sentence.strip()\n",
    "\n",
    "        if cleaned_sentence:\n",
    "            result += cleaned_sentence + \" \"\n",
    "            current_length = len(result.strip())\n",
    "\n",
    "            if current_length >= sentence_length:\n",
    "                return result.strip()\n",
    "\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_content_json(content_json):\n",
    "    \"\"\"assign title and ids to images/ charts, tables, and equations\n",
    "    \"\"\"\n",
    "    img_lst, tbl_lst, formula_lst = [], [], []\n",
    "    i, j, k = 1, 1, 1\n",
    "    for x in content_json:\n",
    "        if x['type'] == 'image':\n",
    "            desc = \"\\n\".join(x.get('img_caption', [])) + \"\\n\" + \"\\n\".join(x.get('img_footnote', []))\n",
    "            ptrn = r\"(pic|picture|img|image|chart|figure|fig)\\s*([0-9]+(?:\\.[0-9]+)?|[0-9]+|[IVXLCDM]+|[a-zA-Z]+)\"\n",
    "            mtch_rslts = re.finditer(ptrn, desc, re.IGNORECASE)\n",
    "\n",
    "            img_ids = []\n",
    "            for match in mtch_rslts:\n",
    "                img_ids.append(match.group(0))  # 直接获取整个匹配的字符串\n",
    "\n",
    "            if len(img_ids) == 0:\n",
    "                img_ids = [f\"Image_Number_{i}\"]\n",
    "                i += 1\n",
    "            x['id'] = img_ids[0]\n",
    "            x['related_ids'] = img_ids[1:]\n",
    "            x['title'] = get_first_lines(desc, 10)\n",
    "            x['description'] = desc\n",
    "            img_lst.append(x)\n",
    "\n",
    "        elif x['type'] == 'table':\n",
    "            desc = \"\\n\".join(x.get('table_caption', [])) + \"\\n\" + \"\\n\".join(x.get('table_footnote', []))\n",
    "            ptrn = r\"(tbl|table|chart|figure|fig)\\s*([0-9]+(?:\\.[0-9]+)?|[0-9]+|[IVXLCDM]+|[a-zA-Z]+)\"\n",
    "            mtch_rslts = re.finditer(ptrn, desc, re.IGNORECASE)\n",
    "\n",
    "            tbl_ids = []\n",
    "            for match in mtch_rslts:\n",
    "                tbl_ids.append(match.group(0))  # 直接获取整个匹配的字符串\n",
    "\n",
    "            if len(tbl_ids) == 0:\n",
    "                tbl_ids = [f\"Table_Number_{j}\"]\n",
    "                j += 1\n",
    "            x['id'] = tbl_ids[0]\n",
    "            x['related_ids'] = tbl_ids[1:]\n",
    "            x['title'] = get_first_lines(desc, 10)\n",
    "            x['description'] = desc\n",
    "            tbl_lst.append(x)\n",
    "\n",
    "        elif x['type'] == 'equation':\n",
    "\n",
    "            desc = x.get('text')\n",
    "            ptrn = r\"(formula|equation|notation|syntax)\\s*([0-9]+(?:\\.[0-9]+)?|[0-9]+|[IVXLCDM]+|[a-zA-Z]+)\"\n",
    "            mtch_rslts = re.finditer(ptrn, desc, re.IGNORECASE)\n",
    "\n",
    "            equation_ids = []\n",
    "            for match in mtch_rslts:\n",
    "                equation_ids.append(match.group(0))  # 直接获取整个匹配的字符串\n",
    "\n",
    "            if len(equation_ids) == 0:\n",
    "                equation_ids = [f\"Equation_Number_{k}\"]\n",
    "                k += 1\n",
    "            x['id'] = equation_ids[0]\n",
    "            x['related_ids'] = equation_ids[1:]\n",
    "            x['title'] = equation_ids[0]\n",
    "            x['description'] = equation_ids[0]\n",
    "            formula_lst.append(x)\n",
    "    return img_lst, tbl_lst, formula_lst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_lst, tbl_lst, formula_lst = process_content_json(content_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify Image Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify markdown image text to better align with standard syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def modify_image_info(md_text, img_lst):\n",
    "    \"\"\"update image information with alternative text, image title, etc.\"\"\"\n",
    "    img_ptrn = re.compile(\n",
    "        r'!\\s*\\[\\s*(?P<alt>.*?)\\s*\\]'  # 匹配 ![alt] alt 部分\n",
    "        r'\\s*\\(\\s*(?P<link>.*?)\\s*'   # 匹配 (link) link 部分\n",
    "        r'(?:'                         # 非捕获组，处理可选的 title 部分\n",
    "        r'(?P<quotetitle>\"(?P<title_double_quote>.*?)\"|'  # 匹配 双引号 title， 命名组 quotetitle 和 title_double_quote\n",
    "        r\"'(?P<title_single_quote>.*?)')\"                 # 匹配 单引号 title， 命名组 title_single_quote\n",
    "        r')?'                          # title 部分可选\n",
    "        r'\\s*\\)'                      # 匹配 ) 括号结尾\n",
    "    )\n",
    "    lines = md_text.splitlines()\n",
    "    img_lst_rvsd = copy.deepcopy(img_lst)\n",
    "    \n",
    "    for idx, line in enumerate(lines):\n",
    "        if line.strip() not in [\"\\n\", \"\\s\", \"\\r\", \"\"]:\n",
    "\n",
    "            # image match logic\n",
    "            img_matches = list(re.finditer(img_ptrn, line))  # 使用 finditer 获取所有匹配项\n",
    "\n",
    "            if img_matches:\n",
    "                for match in reversed(img_matches):  # 逆序遍历匹配项，避免替换位置错乱\n",
    "                    alt_text = match.group(1).strip()\n",
    "                    image_url = match.group(2)\n",
    "                    title = match.group(4).strip() if match.group(4) else None\n",
    "\n",
    "                    for item in img_lst_rvsd:\n",
    "                        if item.get('img_path') == image_url:\n",
    "                            alt_text = item.get('description') if alt_text is None or alt_text == \"\" else alt_text\n",
    "                            title = item.get('img_title', \"\") if title is None or title == \"\" else title\n",
    "                            title = f\"{item.get('id')}: {title}\" if item.get('id').lower() not in title.lower() else title\n",
    "                            img_md = f\"![{alt_text.strip()}]({image_url.strip()} '{title.strip()}')\"\n",
    "\n",
    "                            # 计算替换的起始和结束位置\n",
    "                            start, end = match.span()\n",
    "                            if item.get('org_md_ref') is None:\n",
    "                                item['org_md_ref'] = line[start:end]  # 在image list中添加原始的markdown引用格式 \n",
    "\n",
    "                            lines[idx] = line[:start] + img_md + line[end:]  # 精确替换\n",
    "                            if item.get('mod_md_ref') is None:\n",
    "                                item['mod_md_ref'] = line[:start] + img_md + line[end:]  # 在image list中添加修订后的markdown引用格式 \n",
    "\n",
    "                            # 改进删除重复信息逻辑\n",
    "                            caption = \"\\n\".join(item.get('img_caption')).strip()\n",
    "                            footnote = \"\\n\".join(item.get('img_footnote')).strip()\n",
    "\n",
    "                            # 由于alt_text和title中已经包括了足够的信息，删除上下文中的重复信息\n",
    "                            if caption and len(caption) > 20 and caption != title:\n",
    "                                if idx > 0 and caption in lines[idx-1]:\n",
    "                                    lines[idx-1] = lines[idx-1].replace(caption, \"\")\n",
    "                                if idx < len(lines) - 1 and caption in lines[idx+1]:\n",
    "                                    lines[idx+1] = lines[idx+1].replace(caption, \"\")\n",
    "\n",
    "                            if footnote and len(footnote) > 20 and footnote != title:\n",
    "                                if idx > 0 and footnote in lines[idx-1]:\n",
    "                                    lines[idx-1] = lines[idx-1].replace(footnote, \"\")\n",
    "                                if idx < len(lines) - 1 and footnote in lines[idx+1]:\n",
    "                                    lines[idx+1] = lines[idx+1].replace(footnote, \"\")\n",
    "                            break  # 找到匹配的 item 后跳出循环\n",
    "    return \"\\n\".join(lines), img_lst_rvsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_content_rvsd, img_lst_rvsd = modify_image_info(md_content_rvsd, img_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify Tables Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def modify_tables_info(md_text, tbl_lst):\n",
    "    \"\"\"update table information with alternative text, image title, etc.\"\"\"\n",
    "    \n",
    "    tbl_lst_rvsd = copy.deepcopy(tbl_lst)\n",
    "\n",
    "    lines = md_text.splitlines()\n",
    "\n",
    "    for idx, line in enumerate(lines):  # iterate lines\n",
    "        soup = BeautifulSoup(line, 'html.parser')\n",
    "        table = soup.find('table')\n",
    "\n",
    "        if table:\n",
    "            for item in tbl_lst_rvsd:  # iterate over table list \n",
    "                tbl_desc = item.get('description')\n",
    "                tbl_caption = \"\\n\".join(item.get('table_caption', [])).strip()\n",
    "                tbl_footnote = \"\\n\".join(item.get('table_footnote', [])).strip()\n",
    "                tbl_body = BeautifulSoup(item.get('table_body') , 'html.parser').find('table')\n",
    "                tbl_title = item.get('title')\n",
    "\n",
    "                if table == tbl_body:\n",
    "                    print(table)\n",
    "                    md_caption = table.find('caption')\n",
    "                    if md_caption:\n",
    "                        md_caption.string = tbl_desc      # 将<caption>标签的文本内容替换为 tbl_desc\n",
    "                    else:\n",
    "                        # 如果没有<caption>标签，则创建一个新的<caption>标签并添加到table中\n",
    "                        new_caption_tag = soup.new_tag('caption')\n",
    "                        new_caption_tag.string = tbl_desc\n",
    "                        table.insert(0, new_caption_tag) # 将新的<caption>标签插入到table的开头 (作为第一个子元素)\n",
    "                        \n",
    "                    lines[idx] = f\"<html><body>{table}</body></html>  \"\n",
    "\n",
    "                    # 计算替换的起始和结束位置\n",
    "                    if item.get('org_md_ref') is None:\n",
    "                        item['org_md_ref'] = f\"<html><body>{tbl_body}</body></html>  \" # original table\n",
    "\n",
    "                    if item.get('mod_md_ref') is None:\n",
    "                        item['mod_md_ref'] = f\"<html><body>{table}</body></html>  \"  # table with caption\n",
    "\n",
    "\n",
    "                    # 由于alt_text和title中已经包括了足够的信息，删除上下文中的重复信息\n",
    "                    if tbl_caption and len(tbl_caption) > 20 and tbl_caption != tbl_title:\n",
    "                        if idx > 0 and tbl_caption in lines[idx-1]:\n",
    "                            lines[idx-1] = lines[idx-1].replace(tbl_caption, \"\")\n",
    "                        if idx < len(lines) - 1 and tbl_caption in lines[idx+1]:\n",
    "                            lines[idx+1] = lines[idx+1].replace(tbl_caption, \"\")\n",
    "\n",
    "                    if tbl_footnote and len(tbl_footnote) > 20 and tbl_footnote != tbl_title:\n",
    "                        if idx > 0 and tbl_footnote in lines[idx-1]:\n",
    "                            lines[idx-1] = lines[idx-1].replace(tbl_footnote, \"\")\n",
    "                        if idx < len(lines) - 1 and tbl_footnote in lines[idx+1]:\n",
    "                            lines[idx+1] = lines[idx+1].replace(tbl_footnote, \"\")\n",
    "\n",
    "\n",
    "                    break  # 找到匹配的 item 后跳出循环\n",
    "\n",
    "    return \"\\n\".join(lines), tbl_lst_rvsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4910/1828278122.py:17: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(line, 'html.parser')\n"
     ]
    }
   ],
   "source": [
    "md_content_rvsd, tbl_lst_rvsd = modify_tables_info(md_content_rvsd, tbl_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify Equations Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本处非必要\n",
    "def modify_formula_info(md_text, formula_lst):\n",
    "    \"\"\"update table information with alternative text, image title, etc.\"\"\"\n",
    "    md_content_rvsd = md_text\n",
    "    for formula in formula_lst:\n",
    "        text = formula.get('text', '')\n",
    "        id = formula.get('id', '')\n",
    "        format = formula.get('text_format', '')\n",
    "        md_content_rvsd = md_content_rvsd.replace(text, f\"``'{format} {id}\\n{text}\\n```\")\n",
    "\n",
    "        # 计算替换的起始和结束位置\n",
    "        if item.get('org_md_ref') is None:\n",
    "            item['org_md_ref'] = text # original formula\n",
    "\n",
    "        if item.get('mod_md_ref') is None:\n",
    "            item['mod_md_ref'] = f\"``'{format} {id}\\n{text}\\n```\"  # formula with format information\n",
    "    return md_content_rvsd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markdown Segmentation Proceess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process markdown into segments:\n",
    "- cut markdown content into segments\n",
    "- restore images, tables, equations positions and informations in each segement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "def reorg_section_content(md_content, json_content, level):\n",
    "    title_pattern = re.compile(rf\"^#{{{level}}}\\s+(.+)$\", re.MULTILINE)\n",
    "\n",
    "    sections = []\n",
    "\n",
    "    paragraphs = []\n",
    "    current_section = \"\"\n",
    "    current_title = \"\"\n",
    "\n",
    "    section_num = 1  # Initialize section number\n",
    "    para_id = 1  # initialize pragraph number\n",
    "\n",
    "    for line in md_content.splitlines():\n",
    "        if line.strip() not in [\"\\n\", \"\\s\", \"\\r\", \"\"]:\n",
    "            match = title_pattern.match(line)\n",
    "            if match:\n",
    "                if current_section:  # Save the previous section\n",
    "                    sections.append({\n",
    "                        'level': level,\n",
    "                        'section_num': section_num,\n",
    "                        'title': current_title,\n",
    "                        'text': current_section.strip(),  # Remove leading/trailing whitespace\n",
    "                        'paragraphs': paragraphs\n",
    "                    })\n",
    "                    section_num += 1  # Increment for the next section\n",
    "                \n",
    "                # ready for next section\n",
    "                current_title = match.group(1).strip()\n",
    "                current_section = \"\"  # Start a new section (no title line)\n",
    "                paragraphs = []\n",
    "                para_id = 1\n",
    "            else:\n",
    "                current_section += line + \"\\n\"  # Add to the current section\n",
    "                paragraphs.append({'paragraph_id':f\"paragraph_{para_id}\", 'md_content': line})\n",
    "                para_id += 1\n",
    "\n",
    "    if current_section:  # Save the last section\n",
    "        sections.append({\n",
    "            'level': level,\n",
    "            'section_num': section_num,\n",
    "            'title': current_title,\n",
    "            'text': current_section.strip(),\n",
    "            'paragraphs': paragraphs\n",
    "        })\n",
    "\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_section_image(md_text, img_lst):\n",
    "    \"\"\"restore secction images\"\"\"\n",
    "    lines = md_text.splitlines()\n",
    "\n",
    "    for idx, line in enumerate(lines):\n",
    "        if line.strip() not in [\"\\n\", \"\\s\", \"\\r\", \"\"]:\n",
    "            for img in img_lst:\n",
    "                md_ref = img.get('modified_md_ref').strip()\n",
    "                # image cited in line but not exist in section \n",
    "                if (md_ref not in \"\\n\".join(lines).strip()\n",
    "                    and (img.get('id') in line.strip() or img.get('img_title') in line.strip())):\n",
    "                    lines.insert(idx+1, md_ref)\n",
    "\n",
    "                # line contains image ref but not cited in section\n",
    "                if (md_ref in line.strip()\n",
    "                    and (img.get('id') not in \"\\n\".join(lines).strip() or img.get('img_title') in \"\\n\".join(lines).strip())):\n",
    "                    lines[idx] = line.replace(md_ref, \"  \")\n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = split_markdown_into_dicts(md_file, level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sec in sections:\n",
    "    sec_level = sec.get('level')\n",
    "    sec_num = sec.get('section_num')\n",
    "    sec_title = sec.get('title')\n",
    "    sec_text = sec.get('text')\n",
    "    for item in pdf_toc:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore Images and Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jiezi4ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
